#!/bin/bash

# Update system
yum update -y

# Install Python 3 and pip
yum install -y python3 python3-pip git

# Install Java 11 (required for Kafka tools)
yum install -y java-11-amazon-corretto

# Install Kafka Client Tools
cd /opt
wget https://archive.apache.org/dist/kafka/2.8.1/kafka_2.12-2.8.1.tgz
tar -xzf kafka_2.12-2.8.1.tgz
mv kafka_2.12-2.8.1 kafka
chown -R ec2-user:ec2-user /opt/kafka

# Create Kafka client configuration directory
mkdir -p /opt/kafka/config
chown -R ec2-user:ec2-user /opt/kafka/config

# Create client.properties with SCRAM authentication
cat > /opt/kafka/config/client.properties << 'KAFKA_EOF'
security.protocol=SASL_SSL
sasl.mechanism=SCRAM-SHA-512
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${username}" password="${password}";
KAFKA_EOF

# Set proper permissions
chown ec2-user:ec2-user /opt/kafka/config/client.properties
chmod 600 /opt/kafka/config/client.properties

# Create Kafka aliases for easy use
cat >> /home/ec2-user/.bashrc << 'ALIAS_EOF'

# Kafka Tools Aliases
export KAFKA_HOME=/opt/kafka
export PATH=$PATH:$KAFKA_HOME/bin
alias kafka-topics='$KAFKA_HOME/bin/kafka-topics.sh --bootstrap-server ${bootstrap_brokers} --command-config $KAFKA_HOME/config/client.properties'
alias kafka-console-consumer='$KAFKA_HOME/bin/kafka-console-consumer.sh --bootstrap-server ${bootstrap_brokers} --consumer.config $KAFKA_HOME/config/client.properties'
alias kafka-console-producer='$KAFKA_HOME/bin/kafka-console-producer.sh --bootstrap-server ${bootstrap_brokers} --producer.config $KAFKA_HOME/config/client.properties'
ALIAS_EOF

# Source bashrc for current session
source /home/ec2-user/.bashrc

# ì¶”ê°€ --

# 1. ê°œë°œ ë„êµ¬ ê·¸ë£¹ ì„¤ì¹˜
sudo yum groupinstall -y "Development Tools"

# 2. ê°œë³„ì ìœ¼ë¡œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
sudo yum install -y gcc gcc-c++ make python3-devel librdkafka-devel


# íŠ¹ì • ë²„ì „ ì„¤ì¹˜ ì‹œë„ (ë” ì•ˆì •ì ì¼ ìˆ˜ ìžˆìŒ)
sudo pip3 install confluent-kafka==1.9.2 boto3 certifi

# ì¶”ê°€ --

# Install confluent-kafka and other Python packages

# íŠ¹ì •ë²„ì „ìœ¼ë¡œ ë³€ê²½
# pip3 install confluent-kafka boto3 certifi

# Create project directory
mkdir -p /home/ec2-user/${project_name}
cd /home/ec2-user/${project_name}

# Create MSK Consumer Python script
cat > msk_consumer.py << 'EOF'
#!/usr/bin/env python3

import boto3
import json
import certifi
from confluent_kafka import Consumer
import time
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_msk_credentials():
    """Secrets Managerì—ì„œ MSK SCRAM ìžê²© ì¦ëª… ì¡°íšŒ"""
    try:
        secrets_client = boto3.client('secretsmanager', region_name='ap-northeast-2')
        response = secrets_client.get_secret_value(SecretId='${secret_name}')
        secret = json.loads(response['SecretString'])
        return secret['username'], secret['password']
    except Exception as e:
        logger.error(f"ì‹œí¬ë¦¿ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None, None

def create_msk_consumer():
    """MSK Consumer ìƒì„± ë° SCRAM ì¸ì¦ ì„¤ì •"""
    username, password = get_msk_credentials()
    
    if not username or not password:
        raise Exception("MSK ìžê²© ì¦ëª…ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    logger.info(f"MSK ìžê²© ì¦ëª…ì„ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤: {username}")
    
    # Consumer ì„¤ì •
    config = {
        'bootstrap.servers': '${bootstrap_brokers}',
        'security.protocol': 'SASL_SSL',
        'sasl.mechanism': 'SCRAM-SHA-512',
        'sasl.username': username,
        'sasl.password': password,
        'group.id': f'iot-consumer-group-{int(time.time())}',
        'auto.offset.reset': 'latest',
        'ssl.ca.location': certifi.where(),
        'enable.auto.commit': True,
        'auto.commit.interval.ms': 5000
    }
    
    return Consumer(config)

def main():
    """ë©”ì¸ Consumer ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ðŸš€ Terraform MSK Consumer ì‹œìž‘...")
    
    try:
        consumer = create_msk_consumer()
        consumer.subscribe(['${topic_name}'])
        
        logger.info("ðŸ“¡ ë©”ì‹œì§€ í´ë§ ì‹œìž‘...")
        
        while True:
            msg = consumer.poll(1.0)
            
            if msg is None:
                continue
            if msg.error():
                logger.error(f"Consumer ì˜¤ë¥˜: {msg.error()}")
                continue
                
            # ë©”ì‹œì§€ ì¶œë ¥
            logger.info("=" * 50)
            logger.info("ðŸ“¨ ìˆ˜ì‹ ëœ ë©”ì‹œì§€:")
            logger.info(f"   í† í”½: {msg.topic()}")
            logger.info(f"   íŒŒí‹°ì…˜: {msg.partition()}")
            logger.info(f"   ì˜¤í”„ì…‹: {msg.offset()}")
            logger.info(f"   ê°’: {msg.value().decode('utf-8')}")
            logger.info("=" * 50)
            
    except KeyboardInterrupt:
        logger.info("\nðŸ›‘ Consumer ì¤‘ë‹¨ë¨")
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        consumer.close()
        logger.info("âœ… Consumer ì¢…ë£Œ ì™„ë£Œ")

if __name__ == "__main__":
    main()
EOF

# Make script executable
chmod +x msk_consumer.py

# Change ownership to ec2-user
chown -R ec2-user:ec2-user /home/ec2-user/${project_name}

# Create systemd service for auto-start
cat > /etc/systemd/system/${project_name}-consumer.service << EOF
[Unit]
Description=${project_name} MSK Consumer
After=network.target

[Service]
Type=simple
User=ec2-user
WorkingDirectory=/home/ec2-user/${project_name}
ExecStart=/usr/bin/python3 /home/ec2-user/${project_name}/msk_consumer.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

# Enable and start the service
systemctl daemon-reload
systemctl enable ${project_name}-consumer.service

# Log installation completion
echo "âœ… Terraform EC2 Consumer ì„¤ì¹˜ ì™„ë£Œ!" > /home/ec2-user/installation.log
echo "ðŸ“ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬: /home/ec2-user/${project_name}" >> /home/ec2-user/installation.log
echo "ðŸ”§ Consumer ìŠ¤í¬ë¦½íŠ¸: /home/ec2-user/${project_name}/msk_consumer.py" >> /home/ec2-user/installation.log
echo "âš™ï¸  ì„œë¹„ìŠ¤ ì´ë¦„: ${project_name}-consumer.service" >> /home/ec2-user/installation.log
echo "ðŸš€ ì‹œìž‘ ëª…ë ¹ì–´: sudo systemctl start ${project_name}-consumer" >> /home/ec2-user/installation.log
echo "" >> /home/ec2-user/installation.log
echo "ðŸ”§ Kafka Client Tools ì„¤ì¹˜ ì™„ë£Œ!" >> /home/ec2-user/installation.log
echo "ðŸ“‚ Kafka ì„¤ì¹˜ ê²½ë¡œ: /opt/kafka" >> /home/ec2-user/installation.log
echo "ðŸ”‘ ì¸ì¦ íŒŒì¼: /opt/kafka/config/client.properties" >> /home/ec2-user/installation.log
echo "" >> /home/ec2-user/installation.log
echo "ðŸ“– Kafka ëª…ë ¹ì–´ ì‚¬ìš©ë²•:" >> /home/ec2-user/installation.log
echo "  - í† í”½ ëª©ë¡: kafka-topics --list" >> /home/ec2-user/installation.log
echo "  - í† í”½ ìƒì„¸: kafka-topics --describe --topic ${topic_name}" >> /home/ec2-user/installation.log
echo "  - ë©”ì‹œì§€ í™•ì¸: kafka-console-consumer --topic ${topic_name} --from-beginning" >> /home/ec2-user/installation.log
echo "  - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§: kafka-console-consumer --topic ${topic_name}" >> /home/ec2-user/installation.log

# Create Kafka usage guide
cat > /home/ec2-user/kafka_guide.txt << 'GUIDE_EOF'
ðŸ”§ Kafka Client Tools ì‚¬ìš© ê°€ì´ë“œ

ðŸ“‚ ì„¤ì¹˜ ìœ„ì¹˜: /opt/kafka
ðŸ”‘ ì¸ì¦ íŒŒì¼: /opt/kafka/config/client.properties

ðŸš€ ìžì£¼ ì‚¬ìš©í•˜ëŠ” ëª…ë ¹ì–´:

1. í† í”½ ëª©ë¡ ì¡°íšŒ:
   kafka-topics --list

2. íŠ¹ì • í† í”½ ìƒì„¸ ì •ë³´:
   kafka-topics --describe --topic iot-sensor-data

3. í† í”½ì˜ ëª¨ë“  ë©”ì‹œì§€ í™•ì¸:
   kafka-console-consumer --topic iot-sensor-data --from-beginning

4. ì‹¤ì‹œê°„ ë©”ì‹œì§€ ëª¨ë‹ˆí„°ë§:
   kafka-console-consumer --topic iot-sensor-data

5. ìƒˆë¡œìš´ í† í”½ ìƒì„±:
   kafka-topics --create --topic my-new-topic --partitions 2 --replication-factor 2

6. í† í”½ ì‚­ì œ:
   kafka-topics --delete --topic my-topic

ðŸ’¡ íŒ: ëª¨ë“  ëª…ë ¹ì–´ëŠ” ì´ë¯¸ MSK ì—°ê²° ì •ë³´ì™€ ì¸ì¦ì´ ì„¤ì •ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.
GUIDE_EOF

chown ec2-user:ec2-user /home/ec2-user/kafka_guide.txt
