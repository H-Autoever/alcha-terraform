#!/bin/bash

# Update system
yum update -y

# Install Python 3 and pip
yum install -y python3 python3-pip git

# Install Java 11 (required for Kafka tools)
yum install -y java-11-amazon-corretto

# Install Kafka Client Tools
cd /opt
wget https://archive.apache.org/dist/kafka/2.8.1/kafka_2.12-2.8.1.tgz
tar -xzf kafka_2.12-2.8.1.tgz
mv kafka_2.12-2.8.1 kafka
chown -R ec2-user:ec2-user /opt/kafka

# Create Kafka client configuration directory
mkdir -p /opt/kafka/config
chown -R ec2-user:ec2-user /opt/kafka/config

# Create client.properties with SCRAM authentication
cat > /opt/kafka/config/client.properties << 'KAFKA_EOF'
security.protocol=SASL_SSL
sasl.mechanism=SCRAM-SHA-512
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${username}" password="${password}";
KAFKA_EOF

# Set proper permissions
chown ec2-user:ec2-user /opt/kafka/config/client.properties
chmod 600 /opt/kafka/config/client.properties

# Create Kafka aliases for easy use
cat >> /home/ec2-user/.bashrc << 'ALIAS_EOF'

# Kafka Tools Aliases
export KAFKA_HOME=/opt/kafka
export PATH=$PATH:$KAFKA_HOME/bin
alias kafka-topics='$KAFKA_HOME/bin/kafka-topics.sh --bootstrap-server ${bootstrap_brokers} --command-config $KAFKA_HOME/config/client.properties'
alias kafka-console-consumer='$KAFKA_HOME/bin/kafka-console-consumer.sh --bootstrap-server ${bootstrap_brokers} --consumer.config $KAFKA_HOME/config/client.properties'
alias kafka-console-producer='$KAFKA_HOME/bin/kafka-console-producer.sh --bootstrap-server ${bootstrap_brokers} --producer.config $KAFKA_HOME/config/client.properties'
ALIAS_EOF

# Source bashrc for current session
source /home/ec2-user/.bashrc

# Install Docker
yum install -y docker
systemctl start docker
systemctl enable docker
usermod -a -G docker ec2-user

# Start Kafka UI automatically
docker run -d -p 8080:8080 \
    -e DYNAMIC_CONFIG_ENABLED=true \
    --name kafka-ui \
    provectuslabs/kafka-ui:latest

# ì¶”ê°€ -- (ECR / .env / ì»¨í…Œì´ë„ˆ ì‹¤í–‰)

# ì—ëŸ¬ì‹œ ì¤‘ë‹¨
set -euo pipefail

# ë³€ìˆ˜ëŠ” Terraform templatefileë¡œ ì£¼ìž…ë©ë‹ˆë‹¤
AWS_REGION="${aws_region}"
ECR_REGISTRY="${ecr_registry}"
ECR_REPO_CONNECTOR="${ecr_repository_connector}"
ECR_REPO_FRONTEND="${ecr_repository_frontend}"
IMAGE_TAG="${image_tag}"
CONNECTOR_IMAGE="$ECR_REGISTRY/$ECR_REPO_CONNECTOR:$IMAGE_TAG"
FRONTEND_IMAGE="$ECR_REGISTRY/$ECR_REPO_FRONTEND:$IMAGE_TAG"

# AWS CLI ì„¤ì¹˜ (ì—†ìœ¼ë©´)
if ! command -v aws >/dev/null 2>&1; then
  yum install -y awscli
fi

# ECR ë¡œê·¸ì¸
aws ecr get-login-password --region "$AWS_REGION" | docker login --username AWS --password-stdin "$ECR_REGISTRY"


docker network create --driver=bridge alcha_network



# MongoDB (ì˜ì† ë³¼ë¥¨ í¬í•¨)
docker volume create mongo_data || true
docker rm -f mongodb-server || true
docker pull mongo:latest
docker run -d --name mongodb-server \
  --restart unless-stopped \
  --network alcha_network \
  -p 27017:27017 \
  -v mongo_data:/data/db \
  mongo:latest

# í†µí•© í™˜ê²½íŒŒì¼ ìž‘ì„±(~/.env)
cat > /home/ec2-user/.env <<ENV_EOF
# Kafka
KAFKA_BOOTSTRAP_SERVERS=${bootstrap_brokers}
KAFKA_SECURITY_PROTOCOL=SASL_SSL
KAFKA_SASL_MECHANISM=SCRAM-SHA-512
KAFKA_SASL_USERNAME=${username}
KAFKA_SASL_PASSWORD=${password}

# connector
KAFKA_GROUP_ID=vehicle-data-consumer-group
MONGO_URI=mongodb://mongodb:27017/
MONGO_DB_NAME=vehicle_data_db

# consumer
ALCHA_BACKEND_PORT=${alcha_backend_port}
REDIS_HOST=${redis_host}
REDIS_PORT=${redis_port}
ENV_EOF
chown ec2-user:ec2-user /home/ec2-user/.env
chmod 600 /home/ec2-user/.env

# ì»¤ë„¥í„° ìµœì‹  ì´ë¯¸ì§€ pull & ì‹¤í–‰
docker rm -f alcha-connector || true
docker pull "$CONNECTOR_IMAGE"
docker run -d --name alcha-connector \
  --restart unless-stopped \
  --network alcha_network \
  --env-file /home/ec2-user/.env \
  "$CONNECTOR_IMAGE"

# Start Frontend Server 
docker rm -f alcha-frontend || true
docker pull "$FRONTEND_IMAGE"
docker stop alcha-frontend || true
docker rm alcha-frontend || true
docker run -d --name alcha-frontend -p 5173:3000 "$FRONTEND_IMAGE"

# 1. ê°œë°œ ë„êµ¬ ê·¸ë£¹ ì„¤ì¹˜
sudo yum groupinstall -y "Development Tools"

# 2. ê°œë³„ì ìœ¼ë¡œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
sudo yum install -y gcc gcc-c++ make python3-devel librdkafka-devel


# íŠ¹ì • ë²„ì „ ì„¤ì¹˜ ì‹œë„ (ë” ì•ˆì •ì ì¼ ìˆ˜ ìžˆìŒ)
sudo pip3 install confluent-kafka==1.9.2 boto3 certifi

# ì¶”ê°€ --

# Install confluent-kafka and other Python packages

# íŠ¹ì •ë²„ì „ìœ¼ë¡œ ë³€ê²½
# pip3 install confluent-kafka boto3 certifi

# Log installation completion
echo "âœ… Terraform EC2 Consumer ì„¤ì¹˜ ì™„ë£Œ!" > /home/ec2-user/installation.log
echo "ðŸ“ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬: /home/ec2-user/${project_name}" >> /home/ec2-user/installation.log
echo "ðŸ”§ Consumer ìŠ¤í¬ë¦½íŠ¸: /home/ec2-user/${project_name}/msk_consumer.py" >> /home/ec2-user/installation.log
echo "âš™ï¸  ì„œë¹„ìŠ¤ ì´ë¦„: ${project_name}-consumer.service" >> /home/ec2-user/installation.log
echo "ðŸš€ ì‹œìž‘ ëª…ë ¹ì–´: sudo systemctl start ${project_name}-consumer" >> /home/ec2-user/installation.log
echo "" >> /home/ec2-user/installation.log
echo "ðŸ”§ Kafka Client Tools ì„¤ì¹˜ ì™„ë£Œ!" >> /home/ec2-user/installation.log
echo "ðŸ“‚ Kafka ì„¤ì¹˜ ê²½ë¡œ: /opt/kafka" >> /home/ec2-user/installation.log
echo "ðŸ”‘ ì¸ì¦ íŒŒì¼: /opt/kafka/config/client.properties" >> /home/ec2-user/installation.log
echo "" >> /home/ec2-user/installation.log
echo "ï¿½ Docker ì„¤ì¹˜ ì™„ë£Œ!" >> /home/ec2-user/installation.log
echo "ðŸ“± Kafka UI ì‹¤í–‰ ëª…ë ¹ì–´: docker run -d --name kafka-ui -p 8080:8080 provectuslabs/kafka-ui:latest" >> /home/ec2-user/installation.log
echo "ðŸŒ Kafka UI ì ‘ì†: http://\$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4):8080" >> /home/ec2-user/installation.log
echo "" >> /home/ec2-user/installation.log
echo "ðŸ”§ MSK ë¸Œë¡œì»¤: ${bootstrap_brokers}" >> /home/ec2-user/installation.log
echo "ðŸ‘¤ ì‚¬ìš©ìžëª…: ${username}" >> /home/ec2-user/installation.log
echo "ðŸ” ë¹„ë°€ë²ˆí˜¸: ${password}" >> /home/ec2-user/installation.log
echo "" >> /home/ec2-user/installation.log
echo "ï¿½ðŸ“– Kafka ëª…ë ¹ì–´ ì‚¬ìš©ë²•:" >> /home/ec2-user/installation.log
echo "  - í† í”½ ëª©ë¡: kafka-topics --list" >> /home/ec2-user/installation.log
echo "  - í† í”½ ìƒì„¸: kafka-topics --describe --topic ${topic_name}" >> /home/ec2-user/installation.log
echo "  - ë©”ì‹œì§€ í™•ì¸: kafka-console-consumer --topic ${topic_name} --from-beginning" >> /home/ec2-user/installation.log
echo "  - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§: kafka-console-consumer --topic ${topic_name}" >> /home/ec2-user/installation.log

# Create Kafka usage guide
cat > /home/ec2-user/kafka_guide.txt << 'GUIDE_EOF'
ðŸ”§ Kafka Client Tools ì‚¬ìš© ê°€ì´ë“œ

ðŸ“‚ ì„¤ì¹˜ ìœ„ì¹˜: /opt/kafka
ðŸ”‘ ì¸ì¦ íŒŒì¼: /opt/kafka/config/client.properties

ðŸš€ ìžì£¼ ì‚¬ìš©í•˜ëŠ” ëª…ë ¹ì–´:

1. í† í”½ ëª©ë¡ ì¡°íšŒ:
   kafka-topics --list

2. íŠ¹ì • í† í”½ ìƒì„¸ ì •ë³´:
   kafka-topics --describe --topic iot-sensor-data

3. í† í”½ì˜ ëª¨ë“  ë©”ì‹œì§€ í™•ì¸:
   kafka-console-consumer --topic iot-sensor-data --from-beginning

4. ì‹¤ì‹œê°„ ë©”ì‹œì§€ ëª¨ë‹ˆí„°ë§:
   kafka-console-consumer --topic iot-sensor-data

5. ìƒˆë¡œìš´ í† í”½ ìƒì„±:
   kafka-topics --create --topic my-new-topic --partitions 2 --replication-factor 2

6. í† í”½ ì‚­ì œ:
   kafka-topics --delete --topic my-topic

ðŸ’¡ íŒ: ëª¨ë“  ëª…ë ¹ì–´ëŠ” ì´ë¯¸ MSK ì—°ê²° ì •ë³´ì™€ ì¸ì¦ì´ ì„¤ì •ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.
GUIDE_EOF

chown ec2-user:ec2-user /home/ec2-user/kafka_guide.txt
